{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b36601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "# import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ef39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ianhg/Documents/ACME/MIT_ORC/RL_Opt/.RL_Opt/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: 'bytes' object cannot be interpreted as an integer\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/ianhg/Documents/ACME/MIT_ORC/RL_Opt/.RL_Opt/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: 'bytes' object cannot be interpreted as an integer\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/ianhg/Documents/ACME/MIT_ORC/RL_Opt/.RL_Opt/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: 'bytes' object cannot be interpreted as an integer\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/ianhg/Documents/ACME/MIT_ORC/RL_Opt/.RL_Opt/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/ianhg/Documents/ACME/MIT_ORC/RL_Opt/.RL_Opt/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:773: UserWarning: You are probably loading a DQN model saved with SB3 < 2.4.0, we truncated the optimizer state so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/pull/1963 for more info). Original error: loaded state dict contains a parameter group that doesn't match the size of optimizer's group \n",
      "Note: the model should still work fine, this only a warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# 1. Load Stable-Baselines3 Pretrained DQN LunarLander Model\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Assuming the pretrained model file \"dqn_lunarlander.zip\"\n",
    "# is in your working directory.\n",
    "model_path = \"rl-baselines3-zoo/rl-trained-agents/dqn/LunarLander-v2_1/LunarLander-v2.zip\"\n",
    "\n",
    "# Load the model\n",
    "model = DQN.load(model_path)\n",
    "\n",
    "# Retrieve the underlying PyTorch Q-network\n",
    "policy = model.policy\n",
    "q_net = policy.q_net   # This is a torch.nn.Module that maps state â†’ Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9e8de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 2. Run 1,000 Episodes and Record Every State\n",
    "# -------------------------------------------------------\n",
    "\n",
    "env = gymnasium.make(\"LunarLander-v3\")\n",
    "num_episodes = 1000\n",
    "\n",
    "# Storage: each entry will be a dict\n",
    "# {\n",
    "#     \"state\": np.array([...]),\n",
    "#     \"q_values\": np.array([...])  # shape: (num_actions,)\n",
    "# }\n",
    "records = []\n",
    "\n",
    "for ep in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Convert state to tensor for Q-net\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # 3. Compute Q-values for this state\n",
    "        # -------------------------------------------------------\n",
    "        with torch.no_grad():\n",
    "            q_values = q_net(state_tensor).cpu().numpy().squeeze()\n",
    "\n",
    "        # Let the agent act (you can choose deterministic or stochastic)\n",
    "        action, _ = model.predict(state, deterministic=True)\n",
    "        if np.random.rand() < 0.15:\n",
    "            action = int(env.action_space.sample()) #Randomly sample 15% of the time\n",
    "        if type(action) == np.ndarray:\n",
    "            action = int(action.item())\n",
    "\n",
    "        # Store state and q-values\n",
    "        records.append({\n",
    "            \"state\": state.copy(),\n",
    "            \"q_values\": q_values.copy(),\n",
    "            \"action\": action\n",
    "        })\n",
    "\n",
    "        # Step environment\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88377c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "states_arry = np.array([records[i]['state'] for i in range(len(records))])\n",
    "states_df = pd.DataFrame(states_arry, columns=[\"x\", \"y\", \"x'\", \"y'\", \"angle\", \"angular_velocity\", \"left_contact\", \"right_contact\"])\n",
    "states_df.to_csv(\"ll_states.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1470e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_arry = np.array([records[i]['q_values'] for i in range(len(records))])\n",
    "rewards_df = pd.DataFrame(rewards_arry, columns=[\"Nothing\", \"Left\", \"Main\", \"Right\"])\n",
    "rewards_df.to_csv(\"ll_outcomes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad49fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".RL_Opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
